{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22c3bace-eb9c-4abe-9fc7-3aba36a27be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization,Conv2D,MaxPooling2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1f93a4-6aad-402b-96d8-adb14d8cb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='data/cat_dog_fulls'\n",
    "train_dir='data/cat_dog_fulls/train'\n",
    "test_dir='data/cat_dog_fulls/test'\n",
    "validation_dir='data/cat_dog_fulls/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58eeed1a-57fd-403d-a815-37bb81896cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14000 files belonging to 2 classes.\n",
      "Found 6000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds=tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(150,150),\n",
    "    batch_size=32,\n",
    "    label_mode='binary'\n",
    ")\n",
    "valdiation_ds=tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(150,150),\n",
    "    batch_size=32,\n",
    "    label_mode='binary'\n",
    ")\n",
    "test_ds=tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(150,150),\n",
    "    batch_size=32,\n",
    "    label_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3d64ef-a56b-4e91-a132-ce18dc1340b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_ds = valdiation_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b10bfea7-70a2-4e9b-a144-3b5285a79d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.5526 - accuracy: 0.8099   \n",
      "Epoch 1: val_accuracy improved from -inf to 0.94450, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 45s 90ms/step - loss: 0.5526 - accuracy: 0.8099 - val_loss: 0.4308 - val_accuracy: 0.9445\n",
      "Epoch 2/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.9471 \n",
      "Epoch 2: val_accuracy improved from 0.94450 to 0.96200, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.3605 - accuracy: 0.9471 - val_loss: 0.3002 - val_accuracy: 0.9620\n",
      "Epoch 3/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.9586 \n",
      "Epoch 3: val_accuracy improved from 0.96200 to 0.96600, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.2666 - accuracy: 0.9586 - val_loss: 0.2307 - val_accuracy: 0.9660\n",
      "Epoch 4/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9636 \n",
      "Epoch 4: val_accuracy improved from 0.96600 to 0.97000, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.2133 - accuracy: 0.9636 - val_loss: 0.1886 - val_accuracy: 0.9700\n",
      "Epoch 5/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9679 \n",
      "Epoch 5: val_accuracy improved from 0.97000 to 0.97167, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.1796 - accuracy: 0.9679 - val_loss: 0.1609 - val_accuracy: 0.9717\n",
      "Epoch 6/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9671 \n",
      "Epoch 6: val_accuracy improved from 0.97167 to 0.97333, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.1565 - accuracy: 0.9671 - val_loss: 0.1416 - val_accuracy: 0.9733\n",
      "Epoch 7/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 0.9691 \n",
      "Epoch 7: val_accuracy improved from 0.97333 to 0.97417, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.1408 - accuracy: 0.9691 - val_loss: 0.1272 - val_accuracy: 0.9742\n",
      "Epoch 8/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9691  \n",
      "Epoch 8: val_accuracy improved from 0.97417 to 0.97550, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.1284 - accuracy: 0.9691 - val_loss: 0.1163 - val_accuracy: 0.9755\n",
      "Epoch 9/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9714 \n",
      "Epoch 9: val_accuracy improved from 0.97550 to 0.97633, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 39s 88ms/step - loss: 0.1174 - accuracy: 0.9714 - val_loss: 0.1076 - val_accuracy: 0.9763\n",
      "Epoch 10/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9711 \n",
      "Epoch 10: val_accuracy improved from 0.97633 to 0.97683, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.1121 - accuracy: 0.9711 - val_loss: 0.1010 - val_accuracy: 0.9768\n",
      "Epoch 11/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9716 \n",
      "Epoch 11: val_accuracy did not improve from 0.97683\n",
      "438/438 [==============================] - 37s 85ms/step - loss: 0.1046 - accuracy: 0.9716 - val_loss: 0.0953 - val_accuracy: 0.9768\n",
      "Epoch 12/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9724 \n",
      "Epoch 12: val_accuracy improved from 0.97683 to 0.97733, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.1005 - accuracy: 0.9724 - val_loss: 0.0907 - val_accuracy: 0.9773\n",
      "Epoch 13/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9732 \n",
      "Epoch 13: val_accuracy did not improve from 0.97733\n",
      "438/438 [==============================] - 37s 84ms/step - loss: 0.0969 - accuracy: 0.9732 - val_loss: 0.0868 - val_accuracy: 0.9770\n",
      "Epoch 14/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9731 \n",
      "Epoch 14: val_accuracy did not improve from 0.97733\n",
      "438/438 [==============================] - 37s 85ms/step - loss: 0.0928 - accuracy: 0.9731 - val_loss: 0.0836 - val_accuracy: 0.9770\n",
      "Epoch 15/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9738 \n",
      "Epoch 15: val_accuracy did not improve from 0.97733\n",
      "438/438 [==============================] - 37s 84ms/step - loss: 0.0890 - accuracy: 0.9738 - val_loss: 0.0808 - val_accuracy: 0.9773\n",
      "Epoch 16/30\n",
      "437/438 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9742 \n",
      "Epoch 16: val_accuracy improved from 0.97733 to 0.97767, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.0860 - accuracy: 0.9742 - val_loss: 0.0784 - val_accuracy: 0.9777\n",
      "Epoch 17/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9749 \n",
      "Epoch 17: val_accuracy improved from 0.97767 to 0.97817, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.0847 - accuracy: 0.9749 - val_loss: 0.0763 - val_accuracy: 0.9782\n",
      "Epoch 18/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9751 \n",
      "Epoch 18: val_accuracy improved from 0.97817 to 0.97833, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.0824 - accuracy: 0.9751 - val_loss: 0.0745 - val_accuracy: 0.9783\n",
      "Epoch 19/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9761 \n",
      "Epoch 19: val_accuracy improved from 0.97833 to 0.97867, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.0795 - accuracy: 0.9761 - val_loss: 0.0729 - val_accuracy: 0.9787\n",
      "Epoch 20/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9754 \n",
      "Epoch 20: val_accuracy improved from 0.97867 to 0.97900, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 38s 87ms/step - loss: 0.0777 - accuracy: 0.9754 - val_loss: 0.0715 - val_accuracy: 0.9790\n",
      "Epoch 21/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9756 \n",
      "Epoch 21: val_accuracy improved from 0.97900 to 0.97967, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 40s 93ms/step - loss: 0.0770 - accuracy: 0.9756 - val_loss: 0.0703 - val_accuracy: 0.9797\n",
      "Epoch 22/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9761 \n",
      "Epoch 22: val_accuracy did not improve from 0.97967\n",
      "438/438 [==============================] - 39s 88ms/step - loss: 0.0751 - accuracy: 0.9761 - val_loss: 0.0691 - val_accuracy: 0.9788\n",
      "Epoch 23/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9766 \n",
      "Epoch 23: val_accuracy did not improve from 0.97967\n",
      "438/438 [==============================] - 39s 88ms/step - loss: 0.0748 - accuracy: 0.9766 - val_loss: 0.0682 - val_accuracy: 0.9793\n",
      "Epoch 24/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9777 \n",
      "Epoch 24: val_accuracy did not improve from 0.97967\n",
      "438/438 [==============================] - 38s 88ms/step - loss: 0.0730 - accuracy: 0.9777 - val_loss: 0.0673 - val_accuracy: 0.9790\n",
      "Epoch 25/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9761 \n",
      "Epoch 25: val_accuracy did not improve from 0.97967\n",
      "438/438 [==============================] - 40s 91ms/step - loss: 0.0740 - accuracy: 0.9761 - val_loss: 0.0664 - val_accuracy: 0.9792\n",
      "Epoch 26/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9766 \n",
      "Epoch 26: val_accuracy did not improve from 0.97967\n",
      "438/438 [==============================] - 39s 90ms/step - loss: 0.0727 - accuracy: 0.9766 - val_loss: 0.0657 - val_accuracy: 0.9790\n",
      "Epoch 27/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9767 \n",
      "Epoch 27: val_accuracy did not improve from 0.97967\n",
      "438/438 [==============================] - 41s 94ms/step - loss: 0.0733 - accuracy: 0.9767 - val_loss: 0.0651 - val_accuracy: 0.9797\n",
      "Epoch 28/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9776 \n",
      "Epoch 28: val_accuracy improved from 0.97967 to 0.98000, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 41s 93ms/step - loss: 0.0688 - accuracy: 0.9776 - val_loss: 0.0646 - val_accuracy: 0.9800\n",
      "Epoch 29/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9789 \n",
      "Epoch 29: val_accuracy improved from 0.98000 to 0.98033, saving model to ./eva.weights.h5\n",
      "438/438 [==============================] - 48s 109ms/step - loss: 0.0695 - accuracy: 0.9789 - val_loss: 0.0640 - val_accuracy: 0.9803\n",
      "Epoch 30/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9775 \n",
      "Epoch 30: val_accuracy did not improve from 0.98033\n",
      "438/438 [==============================] - 40s 92ms/step - loss: 0.0681 - accuracy: 0.9775 - val_loss: 0.0634 - val_accuracy: 0.9798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f86093f5540>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_SIZE=150\n",
    "BATCH_SIZE=64\n",
    "LEARNING_RATE=5e-5 \n",
    "pretend_net=EfficientNetB4(weights='imagenet',\n",
    "                           include_top=False,\n",
    "                           input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "for layer in pretend_net.layers:\n",
    "    pretend_net.trainable=False\n",
    "\n",
    "model=Sequential()\n",
    "model.add(pretend_net)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "call=EarlyStopping(patience=5,\n",
    "                   verbose=1,\n",
    "                   monitor='val_loss'\n",
    "                  )\n",
    "check=ModelCheckpoint(filepath='./eva.weights.h5',\n",
    "                      save_best_only=True,\n",
    "                      save_weights_only=True,\n",
    "                      monitor='val_accuracy', #좋은거 판단하는 기준 \n",
    "                      verbose=1\n",
    "                     )\n",
    "\n",
    "model.fit(train_ds,\n",
    "          steps_per_epoch=len(train_ds),\n",
    "          epochs=30,\n",
    "          validation_data=validation_ds,\n",
    "          validation_steps=len(validation_ds),\n",
    "          verbose=1,\n",
    "          callbacks=[call,check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9122fd9-d25b-4dfa-9d0b-33d51cc11dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE=64\n",
    "# def eva(x,y):\n",
    "#     x=tf.cast(x, tf.float32)/255.0\n",
    "#     return x,y\n",
    "\n",
    "# train_ds=train_ds.map(eva,num_parallel_calls=AUTOTUNE)\n",
    "# train_ds=train_ds.cache().shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# validation_ds=validation_ds.map(eva,num_parallel_calls=AUTOTUNE)\n",
    "# validation_ds=validation_ds.cache().shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# test_ds=test_ds.map(eva,num_parallel_calls=AUTOTUNE)\n",
    "# test_ds=test_ds.cache().shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "422c6ab8-c198-45d0-a751-d869ff513554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 64)      1792      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 148, 148, 64)      256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 148, 148, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 72, 72, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 72, 72, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 34, 34, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 34, 34, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 73984)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 73984)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               9470080   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9843329 (37.55 MB)\n",
      "Trainable params: 9842177 (37.54 MB)\n",
      "Non-trainable params: 1152 (4.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# inputs = Input(shape=(150, 150, 3))\n",
    "\n",
    "# # CNN Block 1\n",
    "# x =Conv2D(filters=64,kernel_size=(3,3))(inputs)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "# # CNN Block 2\n",
    "# x = Conv2D(filters=128,kernel_size=(3,3))(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "# # CNN Block 3\n",
    "# x = Conv2D(filters=256,\n",
    "#               kernel_size=(3,3))(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "# # FC Layer\n",
    "# x = Flatten()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(128)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "# # 출력층 (이진 분류)\n",
    "# outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# # 모델 정의\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# # 컴파일\n",
    "# model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # 모델 구조 확인\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5809cfa6-0275-456c-9760-a6692196664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "438/438 [==============================] - 48s 98ms/step - loss: 0.5556 - accuracy: 0.7239 - val_loss: 0.5236 - val_accuracy: 0.7335\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 76s 174ms/step - loss: 0.3935 - accuracy: 0.8221 - val_loss: 0.4425 - val_accuracy: 0.7972\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 27s 63ms/step - loss: 0.3170 - accuracy: 0.8629 - val_loss: 0.5018 - val_accuracy: 0.7837\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 21s 49ms/step - loss: 0.2559 - accuracy: 0.8980 - val_loss: 0.4228 - val_accuracy: 0.8062\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 30s 69ms/step - loss: 0.2102 - accuracy: 0.9169 - val_loss: 0.4540 - val_accuracy: 0.8003\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 22s 49ms/step - loss: 0.1722 - accuracy: 0.9391 - val_loss: 0.4897 - val_accuracy: 0.7885\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 21s 49ms/step - loss: 0.1455 - accuracy: 0.9494 - val_loss: 0.4322 - val_accuracy: 0.8157\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 22s 49ms/step - loss: 0.1187 - accuracy: 0.9602 - val_loss: 0.4583 - val_accuracy: 0.8230\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 24s 54ms/step - loss: 0.1069 - accuracy: 0.9652 - val_loss: 0.4809 - val_accuracy: 0.8163\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 22s 49ms/step - loss: 0.0916 - accuracy: 0.9708 - val_loss: 0.5310 - val_accuracy: 0.8117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f872473a1a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=validation_ds,\n",
    "#     epochs=10\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec96fd-473a-4e68-b369-e8e39db9f92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffec0361-9457-4d5c-aa61-23a8cacbe150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               1048704   \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15764033 (60.14 MB)\n",
      "Trainable params: 1049089 (4.00 MB)\n",
      "Non-trainable params: 14714944 (56.13 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 31s 66ms/step - loss: 0.2193 - accuracy: 0.9076 - val_loss: 0.1368 - val_accuracy: 0.9495\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 29s 67ms/step - loss: 0.1454 - accuracy: 0.9415 - val_loss: 0.1203 - val_accuracy: 0.9533\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 45s 102ms/step - loss: 0.1242 - accuracy: 0.9507 - val_loss: 0.1145 - val_accuracy: 0.9570\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 29s 66ms/step - loss: 0.1108 - accuracy: 0.9587 - val_loss: 0.1185 - val_accuracy: 0.9533\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 31s 71ms/step - loss: 0.1010 - accuracy: 0.9615 - val_loss: 0.1140 - val_accuracy: 0.9550\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 31s 71ms/step - loss: 0.0899 - accuracy: 0.9670 - val_loss: 0.1097 - val_accuracy: 0.9570\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.0817 - accuracy: 0.9705 - val_loss: 0.1127 - val_accuracy: 0.9550\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.0745 - accuracy: 0.9732 - val_loss: 0.1083 - val_accuracy: 0.9578\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 30s 69ms/step - loss: 0.0707 - accuracy: 0.9738 - val_loss: 0.1114 - val_accuracy: 0.9568\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 0.1143 - val_accuracy: 0.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f86482723b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16  # 예시로 VGG16 사용\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 사전 학습된 VGG16 모델을 불러옵니다 (ImageNet 데이터셋으로 학습된 모델)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Fine-tuning을 위한 모델 구성\n",
    "inputs = Input(shape=(150, 150, 3))\n",
    "\n",
    "# VGG16의 베이스 모델을 고정 (학습되지 않도록)\n",
    "x = base_model(inputs)\n",
    "x = Flatten()(x)  # 출력층으로 플래튼\n",
    "\n",
    "# FC Layer\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# 출력층 (이진 분류)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# 전체 모델 정의\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Fine-tuning: VGG16 모델의 가중치는 동결하고, 마지막 Dense 레이어만 학습\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # VGG16의 모든 레이어를 학습되지 않도록 설정\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 구조 확인\n",
    "model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(train_ds, validation_data=validation_ds, epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
