{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a3d156-cd17-4101-adbe-cced7c6c1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "eva=pd.read_csv('Number_Detection/number_csv/data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b327d83-8d34-499b-bcc8-9548850b9b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>height</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.png</td>\n",
       "      <td>219</td>\n",
       "      <td>246</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>219</td>\n",
       "      <td>323</td>\n",
       "      <td>81</td>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>32</td>\n",
       "      <td>77</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.png</td>\n",
       "      <td>32</td>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.png</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  height  left  top  width  label\n",
       "0    1.png     219   246   77     81      1\n",
       "1    1.png     219   323   81     96      9\n",
       "2    2.png      32    77   29     23      2\n",
       "3    2.png      32    98   25     26      3\n",
       "4    3.png      15    17    5      8      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eva.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4249dbbb-3484-41f9-a821-765b8084665a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename    0\n",
      "height      0\n",
      "left        0\n",
      "top         0\n",
      "width       0\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(eva.isnull().sum())\n",
    "# print(eva.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ed8890-adfd-4b03-904d-e1ce38cabc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        filename  xmin  ymin  xmax  ymax  label\n",
      "0          1.png   246    77   327   296      1\n",
      "1          1.png   323    81   419   300      9\n",
      "2          2.png    77    29   100    61      2\n",
      "3          2.png    98    25   124    57      3\n",
      "4          3.png    17     5    25    20      2\n",
      "...          ...   ...   ...   ...   ...    ...\n",
      "73252  33401.png    34     6    59    46      2\n",
      "73253  33401.png    61     4    86    44      2\n",
      "73254  33402.png    35    10    42    35      1\n",
      "73255  33402.png    44     8    59    33      6\n",
      "73256  33402.png    62     9    79    34      9\n",
      "\n",
      "[73257 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('/home/eva/jupyter_home/Number_Detection/number_csv/data.csv')\n",
    "\n",
    "# 'xmin', 'ymin', 'xmax', 'ymax' 컬럼 계산\n",
    "df['xmin'] = df['left']\n",
    "df['ymin'] = df['top']\n",
    "df['xmax'] = df['left'] + df['width']\n",
    "df['ymax'] = df['top'] + df['height']\n",
    "\n",
    "# 새로운 CSV 파일로 저장\n",
    "df_xyxy = df[['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'label']]\n",
    "df_xyxy.to_csv('bounding_boxes_xyxy.csv', index=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(df_xyxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254ae93a-d4a8-4fe4-a540-c8fd3b1e960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.png</td>\n",
       "      <td>246</td>\n",
       "      <td>77</td>\n",
       "      <td>327</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>323</td>\n",
       "      <td>81</td>\n",
       "      <td>419</td>\n",
       "      <td>300</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>77</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.png</td>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>124</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.png</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  xmin  ymin  xmax  ymax  label\n",
       "0    1.png   246    77   327   296      1\n",
       "1    1.png   323    81   419   300      9\n",
       "2    2.png    77    29   100    61      2\n",
       "3    2.png    98    25   124    57      3\n",
       "4    3.png    17     5    25    20      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_xyxy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e2e8235-f50c-43da-8d6d-785685b4668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 9 2 3 5 8 7 4 6 0]\n"
     ]
    }
   ],
   "source": [
    "print(df_xyxy['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883169f9-0032-4dd6-902d-8508efaf9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_dir, validation_dir =train_test_split(df_xyxy,\n",
    "                                           test_size=0.2,\n",
    "                                           stratify=df_xyxy['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "410f1a8d-b7a6-4dc5-88e1-ac964a008144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Number_Detection'\n",
      "/home/eva/jupyter_home/Number_Detection\n"
     ]
    }
   ],
   "source": [
    "cd Number_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c064ce3-b816-47fb-98b2-023f8be7a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASCAL VOC 형태로 만들어야 함 \n",
    "# images -> 현재 train/ 안에 저장되어 있음 => pascal_voc_data/JPEGImages/ 로 복사\n",
    "# pascal_voc_data/Annotations/ 에 annotation (.xml) 파일을 생성\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "main_dir='/home/eva/jupyter_home/Number_Detection'\n",
    "def make_xml(df):\n",
    "    grouped=df.groupby('filename')\n",
    "    for filename, group in grouped:\n",
    "        xml_name = os.path.splitext(filename)[0] + '.xml'\n",
    "        path = os.path.join(main_dir, 'train', filename)\n",
    "        img = cv2.imread(path)\n",
    "        \n",
    "        if img is not None:\n",
    "            h, w, c = img.shape\n",
    "        else:\n",
    "            print(f\"이미지 로딩 실패: {filename}\")\n",
    "            continue\n",
    "        with open(os.path.join(main_dir,'VOCdevkit/voc2007/Annotations',xml_name), 'w' ) as f:\n",
    "            f.write(f'''\n",
    "            <annotation>\n",
    "                <folder>JPEGImages</folder>\n",
    "                <filename>{filename}</filename>\n",
    "                <path>{path}</path>\n",
    "                <size>\n",
    "                    <width>{w}</width>\n",
    "                    <height>{h}</height>\n",
    "                    <depth>{c}</depth>\n",
    "                </size>''')\n",
    "            for _, row in group.iterrows():\n",
    "                filename=row['filename']\n",
    "                xml_name=row['filename'].split('.')[0]+'.xml'\n",
    "                xmin=row['xmin']\n",
    "                xmax=row['xmax']\n",
    "                ymin=row['ymin']\n",
    "                ymax=row['ymax']\n",
    "                label=row['label']\n",
    "                f.write(f'''\n",
    "                    <object>\n",
    "                        <name>{label}</name>\n",
    "                        <bndbox>\n",
    "                            <xmin>{xmin}</xmin>\n",
    "                            <ymin>{ymin}</ymin>\n",
    "                            <xmax>{xmax}</xmax>\n",
    "                            <ymax>{ymax}</ymax>\n",
    "                        </bndbox>\n",
    "                    </object>''')\n",
    "            f.write('</annotation>')\n",
    "\n",
    "make_xml(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa0d04-3c4e-49c5-9e57-41be4cab07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 JPEGImages 로cp하기 ->Number_Detection/VOCdevkit/voc2007/JPEGImages 여기로 \n",
    " cp -r /home/eva/jupyter_home/Number_Detection/train . \n",
    "#그리고 imagesets을 txt로 마들어서 가져온다 train/val 80:20으로 해서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8b6d4fc-580a-4f73-846e-ecd46c788d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eva/jupyter_home/TF2_Object_Detection/models/research\n"
     ]
    }
   ],
   "source": [
    "#tf_recor을 생성하기 위해 research/models안에 있는 object_detection으로 가야하기 때문에 pwd 했을때 아래와 같은 경로에 있어야 한다  \n",
    "#/home/eva/jupyter_home/TF2_Object_Detection/models/research\n",
    "cd research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0adab40b-8301-409c-a408-9edd7be981df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# VOC 클래스 목록 (20 classes)\n",
    "VOC_CLASSES = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "class_name_to_id = {name: i for i, name in enumerate(VOC_CLASSES)}\n",
    "\n",
    "def parse_voc_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find(\"filename\").text\n",
    "    size = root.find(\"size\")\n",
    "    width = int(size.find(\"width\").text)\n",
    "    height = int(size.find(\"height\").text)\n",
    "\n",
    "    bboxes = []\n",
    "    labels = []\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = obj.find(\"name\").text\n",
    "        label = class_name_to_id[name]\n",
    "\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = int(float(bbox.find(\"xmin\").text))\n",
    "        ymin = int(float(bbox.find(\"ymin\").text))\n",
    "        xmax = int(float(bbox.find(\"xmax\").text))\n",
    "        ymax = int(float(bbox.find(\"ymax\").text))\n",
    "\n",
    "        bboxes.append([xmin, ymin, xmax, ymax])\n",
    "        labels.append(label)\n",
    "\n",
    "    return filename, width, height, bboxes, labels\n",
    "\n",
    "def create_tf_example(image_path, xml_path):\n",
    "    filename, width, height, bboxes, labels = parse_voc_xml(xml_path)\n",
    "\n",
    "    with tf.io.gfile.GFile(image_path, 'rb') as fid:\n",
    "        encoded_image = fid.read()\n",
    "\n",
    "    xmins = [box[0] / width for box in bboxes]\n",
    "    ymins = [box[1] / height for box in bboxes]\n",
    "    xmaxs = [box[2] / width for box in bboxes]\n",
    "    ymaxs = [box[3] / height for box in bboxes]\n",
    "\n",
    "    classes_text = [VOC_CLASSES[label].encode('utf8') for label in labels]\n",
    "    classes = labels\n",
    "\n",
    "    feature = {\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image])),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode('utf8')])),\n",
    "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
    "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
    "    }\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example\n",
    "\n",
    "def generate_tfrecord(voc_dir, split_txt, output_path):\n",
    "    annotation_dir = os.path.join(voc_dir, 'Annotations')\n",
    "    image_dir = os.path.join(voc_dir, 'JPEGImages')\n",
    "\n",
    "    with tf.io.TFRecordWriter(output_path) as writer:\n",
    "        with open(split_txt, 'r') as f:\n",
    "            lines = f.read().strip().splitlines()\n",
    "\n",
    "        for img_id in lines:\n",
    "            xml_path = os.path.join(annotation_dir, f\"{img_id}.xml\")\n",
    "            img_path = os.path.join(image_dir, f\"{img_id}.png\")\n",
    "\n",
    "            if os.path.exists(xml_path) and os.path.exists(img_path):\n",
    "                example = create_tf_example(img_path, xml_path)\n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "VOC_ROOT_DIR = '/home/eva/jupyter_home/Number_Detection'\n",
    "\n",
    "# 실행\n",
    "generate_tfrecord(\n",
    "    voc_dir=VOC_ROOT_DIR + \"/VOCdevkit/voc2007\",\n",
    "    split_txt=VOC_ROOT_DIR + \"/VOCdevkit/voc2007/ImageSets/Main/train.txt\",\n",
    "    output_path=VOC_ROOT_DIR + \"/num_voc2007_train.tfrecord\" #만들어 지는 파일  \n",
    ")\n",
    "\n",
    "generate_tfrecord(\n",
    "    voc_dir=VOC_ROOT_DIR + \"/VOCdevkit/voc2007\",\n",
    "    split_txt=VOC_ROOT_DIR + \"/VOCdevkit/voc2007/ImageSets/Main/val.txt\",\n",
    "    output_path=VOC_ROOT_DIR + \"/num_voc2007_val.tfrecord\"   #만들어 지는 파일\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83f85e85-654e-41a1-9071-b7b245d47df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eva/jupyter_home/Number_Detection\n"
     ]
    }
   ],
   "source": [
    "cd Number_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f80f662-2a67-4606-ac13-0d1e056a4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 512\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    features = {\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "\n",
    "    parsed = tf.io.parse_single_example(example, features)\n",
    "    image = tf.image.decode_jpeg(parsed['image/encoded'], channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "\n",
    "    xmins = tf.sparse.to_dense(parsed['image/object/bbox/xmin'])\n",
    "    ymins = tf.sparse.to_dense(parsed['image/object/bbox/ymin'])\n",
    "    xmaxs = tf.sparse.to_dense(parsed['image/object/bbox/xmax'])\n",
    "    ymaxs = tf.sparse.to_dense(parsed['image/object/bbox/ymax'])\n",
    "    labels = tf.sparse.to_dense(parsed['image/object/class/label'])\n",
    "\n",
    "    boxes = tf.stack([xmins, ymins, xmaxs, ymaxs], axis=-1)\n",
    "\n",
    "    return {\n",
    "        \"images\": image,\n",
    "        \"bounding_boxes\": {\n",
    "            \"boxes\": boxes,\n",
    "            \"classes\": tf.cast(labels, tf.int32),\n",
    "        }\n",
    "    }\n",
    "\n",
    "def load_dataset(tfrecord_path, batch_size=8):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    dataset = dataset.map(parse_tfrecord, \n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # padded_batch 필수\n",
    "    dataset = dataset.shuffle(1000).padded_batch(\n",
    "        batch_size,\n",
    "        padded_shapes={\n",
    "            \"images\": [IMAGE_SIZE, IMAGE_SIZE, 3],\n",
    "            \"bounding_boxes\": {\n",
    "                \"boxes\": [None, 4],\n",
    "                \"classes\": [None]\n",
    "            }\n",
    "        },\n",
    "        drop_remainder=True\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "#데이터 셋 준비 \n",
    "train_ds = load_dataset(\"./num_voc2007_train.tfrecord\", \n",
    "                        batch_size=8)\n",
    "\n",
    "val_ds = load_dataset(\"./num_voc2007_val.tfrecord\", \n",
    "                        batch_size=8)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0563407b-aa7b-4454-9e64-d40ac8c7480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/2 404 \n",
      "\u001b[1mcontent-length\u001b[0m: 134\n",
      "\u001b[1mcontent-type\u001b[0m: text/html; charset=UTF-8\n",
      "\u001b[1mdate\u001b[0m: Tue, 13 May 2025 02:46:18 GMT\n",
      "\u001b[1malt-svc\u001b[0m: h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!curl -I https://www.kaggle.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414b6133-f8a2-4eb8-bcd7-b893fe0ab29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_cv.models import RetinaNet\n",
    "#이미 만들어 놓은 모델을 가지고 와서 만들어야 함! : from_preset() \n",
    "#어떤 preset()이 있는지 확인 필요함!\n",
    "model = RetinaNet.from_preset(\n",
    "    'resnet50',\n",
    "    bounding_box_format='xyxy',\n",
    "    num_classes=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d5b9ac0-30ed-4162-934b-90f86375b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "             classification_loss='focal',\n",
    "             box_loss='smoothl1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a37f81b-320d-41a6-a1ad-ea69875c3ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eva/jupyter_home/Number_Detection\n"
     ]
    }
   ],
   "source": [
    "cd Number_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ec226-6738-426a-a572-d9bde0ea9570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    256/Unknown - 108s 337ms/step - loss: 0.0000e+00 - box_loss: 0.0000e+00 - classification_loss: 0.0000e+00 - percent_boxes_matched_with_anchor: 0.4371"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds,\n",
    "          batch_size=16,\n",
    "          epochs=10,\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4f28029-6412-4225-a00f-d6d2ca98d04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eva/jupyter_home/Number_Detection\n"
     ]
    }
   ],
   "source": [
    "cd Number_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa959a-9212-4720-be2f-eb893eb59b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_eva",
   "language": "python",
   "name": "keras_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
