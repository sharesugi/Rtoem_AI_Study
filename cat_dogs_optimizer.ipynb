{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f692c7-b158-497e-93e4-b057c2be74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import warnings\n",
    "import  optuna\n",
    "warnings.filterwarnings('ignore') #경고 메세지 창을 무시하기 \n",
    "train_dir = './data/cat_dog_small/train'\n",
    "validation_dir = './data/cat_dog_small/validation'\n",
    "test_dir = './data/cat_dog_small/test'\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1/255,\n",
    "                                rotation_range=30,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                vertical_flip=False,\n",
    "                                fill_mode='nearest')\n",
    "validation_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1/255,\n",
    "                                rotation_range=30,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                vertical_flip=False,\n",
    "                                fill_mode='nearest')\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,\n",
    "                                                 classes=['cats','dogs'],\n",
    "                                                 target_size=(150,150),\n",
    "                                                 batch_size=20,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "validation_generator=validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                 classes=['cats','dogs'],\n",
    "                                                 target_size=(150,150),\n",
    "                                                 batch_size=20,\n",
    "                                                 class_mode='binary')\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,\n",
    "                                                 classes=['cats','dogs'],\n",
    "                                                 target_size=(150,150),\n",
    "                                                 batch_size=20,\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d574ca95-0404-4693-851b-1f708bb12bf9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 655ms/step - accuracy: 0.7683 - loss: 0.5238 - val_accuracy: 0.8040 - val_loss: 0.4675\n",
      "Epoch 2/30\n",
      "\u001b[1m 66/100\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 455ms/step - accuracy: 0.8269 - loss: 0.3786"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     22\u001b[0m call \u001b[38;5;241m=\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     23\u001b[0m                      monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m                      verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     25\u001b[0m                      restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m check\u001b[38;5;241m=\u001b[39mModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./e.weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m                      save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m                      save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m                       monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvall_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m                       verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_base=VGG16(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(150,150,3))\n",
    "model_base.trainable=False\n",
    "model=Sequential()\n",
    "model.add(model_base)\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "call =EarlyStopping(patience=5,\n",
    "                     monitor='val_loss',\n",
    "                     verbose=1,\n",
    "                     restore_best_weights=True)\n",
    "\n",
    "check=ModelCheckpoint(filepath='./e.weights.h5',\n",
    "                     save_best_only=True,\n",
    "                     save_weights_only=True,\n",
    "                      monitor='vall_accuracy',\n",
    "                      verbose=1)\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=100,\n",
    "          epochs=30,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=50,\n",
    "          callbacks=[call, check],\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47c49157-97f0-4432-88a6-58040abdfd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               1048704   \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15764033 (60.14 MB)\n",
      "Trainable params: 1049089 (4.00 MB)\n",
      "Non-trainable params: 14714944 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a02c62-19c6-454d-9fad-c334aaa049ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fine tuning(미세 조정) 상위 filter부분의 이용해서 좀 더 나에게 맞는 모델을 만듬\n",
    "#어떻게 얼마나 뒤에 filter을 손봐야 하는가 -> 대략 20% 정도 \n",
    "#학습을 한 상태에서 이걸 하고 다시 모델을 학습함!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os  #폴더경로 생성하기 위해서 사용함 !\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #입력데이터 처리\n",
    "from tensorflow.keras.applications  import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation # activation하기 전에 드렁가야 함 !\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import warnings #경고 메세지 창을 징귀\n",
    "warnings.filterwarnings('ignore') #경고 메세지 창을 무시하기 \n",
    "train_dir = './data/cat_dog_small/train'\n",
    "validation_dir = './data/cat_dog_small/validation'\n",
    "test_dir = './data/cat_dog_small/test'\n",
    "\n",
    "\n",
    "#ImageDataGenerator 를 생성, 2개 필요 ->  어떤식으로 데이터를 가죠올 거니? \n",
    "#trian 1개 ->증식설정 필요/ Validation 1게 -> 증식 필요없음\n",
    "train_datagen=ImageDataGenerator(rescale=1/255,\n",
    "                                rotation_range=40,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest') # 변경하고 남은 부분을 근처와 비슷하게 채워라\n",
    "                                # vertical_flit=True) # 위아래 위치를 바꿈 (사용 안하는거 추천!)  \n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "#이미지 데이터 generator설정 잡기\n",
    "train_generator =train_datagen.flow_from_directory(train_dir,\n",
    "                                                  classes=['cats','dogs'],\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=20,\n",
    "                                                  class_mode='binary')\n",
    "validation_generator=validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                           classes=['cats','dogs'],\n",
    "                                                           target_size=(150,150),\n",
    "                                                           batch_size=20,\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "\n",
    "#model구현\n",
    "model_base=VGG16(weights='imagenet',\n",
    "                input_shape=(150,150,3),\n",
    "                include_top=False)\n",
    "\n",
    "#model_base에 대해서 False로 해서 filter값을 변경하지 않게 함(동결)\n",
    "model_base_trainable=False\n",
    "model=Sequential()\n",
    "#hiddne layer\n",
    "model.add(model_base) #내가 만든 model에 앞부분 filter에 model_base가 들어간다 이말임! -> 4차원\n",
    "model.add(Flatten())  #위에 4차원을 1차원으로 만들어줌 ! : Flattne으 역활\n",
    "model.add(Dense(units=128))\n",
    "model.add(BatchNormalization()) #성능 향상을위해 사용함!\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(rate=0.2)) #무조건 activation두이 넣어야 함 !!! -> batchnomal이 있으니간 0.2정도만 \n",
    "#output lyaer\n",
    "\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "             loss='binary_crossentropy', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "call=EarlyStopping(patience=5,\n",
    "                  monitor='val_loss',\n",
    "                  verbose=1,\n",
    "                  restore_best_weights=True) #그떄까지 가장 좋은 값 return \n",
    "\n",
    "check=ModelCheckpoint(filepath='./f.weights.h5',\n",
    "                     save_best_only=True,\n",
    "                     save_weights_only=True,\n",
    "                     monitor='val_accuracy',\n",
    "                     verbose=1)\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=100,\n",
    "          epochs=30,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=50,\n",
    "          verbose=1,\n",
    "          callbacks=[call])\n",
    "                  \n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11fa6f-14da-48b5-b202-d8f5a444c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine_tuning\n",
    "model_base.trainable=True\n",
    "rate=len(model_base.layers)\n",
    "fin_len=int(rate*0.7)\n",
    "\n",
    "for layer in model_base.layers[:fin_len]:  \n",
    "    layer.trainable = False \n",
    "for layer in model_base.layers[fin_len:]:  \n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model_base.summary()\n",
    "\n",
    "# Model 학습(Fine Tuning)\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=100,\n",
    "          epochs=15,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=50,\n",
    "          callbacks=[call, check],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37798233-1b57-4ca8-ac02-1f05eefd7e21",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow_hub) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow_hub) (4.25.7)\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow_hub)\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow<2.20,>=2.19 (from tf-keras>=2.14.1->tensorflow_hub)\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.71.0)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy>=1.12.0 (from tensorflow_hub)\n",
      "  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.13.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
      "  Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/eva/anaconda3/envs/tf_gpu/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (397 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, optree, numpy, mdurl, tensorboard, ml-dtypes, markdown-it-py, rich, keras, tensorflow, tf-keras, tensorflow_hub\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.13.0\n",
      "    Uninstalling tensorboard-2.13.0:\n",
      "      Successfully uninstalled tensorboard-2.13.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.13.1\n",
      "    Uninstalling keras-2.13.1:\n",
      "      Successfully uninstalled keras-2.13.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.13.0\n",
      "    Uninstalling tensorflow-2.13.0:\n",
      "      Successfully uninstalled tensorflow-2.13.0\n",
      "Successfully installed keras-3.9.2 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.9 numpy-2.1.3 optree-0.15.0 rich-14.0.0 tensorboard-2.19.0 tensorflow-2.19.0 tensorflow_hub-0.16.1 tf-keras-2.19.0\n"
     ]
    }
   ],
   "source": [
    "#EfficientNet \n",
    "!pip install tensorflow_hub\n",
    "#이미 분류 / 전이 학습 / 영상 처리 및 분석 에서 사용함 \n",
    "#고해상도 이미지 처리/ 제약된 계산 자원/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fac0ac5-30df-4c64-9ead-6a8a057246ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_hub as hub\n",
    "# model_base = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/google/efficientnetv2-xl-21k-ft1k/1\",\n",
    "#                                                trainable=True,\n",
    "#                                                input_shape=(150,150,3)])\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "model_base= EfficientNetB4(weights='imagenet',\n",
    "                           input_shape=(),\n",
    "                           include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "98c4ac48-f1b2-4a6d-959f-5cc65f819578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "from tensorflow.keras.applications import EfficientNetB4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee994fe-ab2d-4c9a-a17b-b0d0752a819d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os  #폴더경로 생성하기 위해서 사용함 !\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #입력데이터 처리\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import warnings #경고 메세지 창을 징귀\n",
    "warnings.filterwarnings('ignore') #경고 메세지 창을 무시하기 \n",
    "train_dir = './data/cat_dog_small/train'\n",
    "validation_dir = './data/cat_dog_small/validation'\n",
    "test_dir = './data/cat_dog_small/test'\n",
    "\n",
    "\n",
    "#ImageDataGenerator 를 생성, 2개 필요 ->  어떤식으로 데이터를 가죠올 거니? \n",
    "#trian 1개 ->증식설정 필요/ Validation 1게 -> 증식 필요없음\n",
    "train_datagen=ImageDataGenerator(rescale=1/255,\n",
    "                                rotation_range=40,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest') # 변경하고 남은 부분을 근처와 비슷하게 채워라\n",
    "                                # vertical_flit=True) # 위아래 위치를 바꿈 (사용 안하는거 추천!)  \n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "#이미지 데이터 generator설정 잡기\n",
    "train_generator =train_datagen.flow_from_directory(train_dir,\n",
    "                                                  classes=['cats','dogs'],\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=20,\n",
    "                                                  class_mode='binary')\n",
    "validation_generator=validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                           classes=['cats','dogs'],\n",
    "                                                           target_size=(150,150),\n",
    "                                                           batch_size=20,\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "\n",
    "#model구현\n",
    "\n",
    "\n",
    "model_base = VGG16(weights='imagenet',\n",
    "                   include_top=False,\n",
    "                   input_shape=(150,150,3))\n",
    "\n",
    "#model_base에 대해서 False로 해서 filter값을 변경하지 않게 함(동결)\n",
    "model_base_trainable=False\n",
    "model=Sequential()\n",
    "#hiddne layer\n",
    "model.add(model_base) #내가 만든 model에 앞부분 filter에 model_base가 들어간다 이말임! -> 4차원\n",
    "model.add(Flatten())  #위에 4차원을 1차원으로 만들어줌 ! : Flattne으 역활\n",
    "model.add(Dense(units=128))\n",
    "model.add(BatchNormalization()) #성능 향상을위해 사용함!\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(rate=0.3)) #무조건 activation두이 넣어야 함 !!! -> batchnomal이 있으니간 0.2정도만 \n",
    "#output lyaer\n",
    "\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init=1e-5\n",
    "model.compile(optimizer=Adam(learning_rate=init),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "class LRFinderCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, min_lr=1e-8, max_lr=10, steps=100):\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.total_steps = steps\n",
    "        self.history = {'lr': [],\n",
    "                        'loss': []}\n",
    "        \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        lr = self.min_lr * (self.max_lr / self.min_lr) ** (batch / self.total_steps)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "        self.history['lr'].append(lr)\n",
    "        self.history['loss'].append(logs['loss'])\n",
    "\n",
    "lr_finder = LRFinderCallback(min_lr=1e-8, max_lr=1, steps=100)\n",
    "\n",
    "call=EarlyStopping(patience=5,\n",
    "                  monitor='val_loss',\n",
    "                  verbose=1,\n",
    "                  restore_best_weights=True) #그떄까지 가장 좋은 값 return \n",
    "\n",
    "check=ModelCheckpoint(filepath='./fl.weights.h5',\n",
    "                     save_best_only=True,\n",
    "                     save_weights_only=True,\n",
    "                     monitor='val_accuracy',\n",
    "                     verbose=1)\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=100,\n",
    "          epochs=30,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=50,\n",
    "          callbacks=[lr_finder, call, check],\n",
    "          verbose=1)\n",
    "\n",
    "plt.plot(lr_finder.history['lr'], lr_finder.history['loss'])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
